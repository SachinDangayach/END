








<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>Jupyter Notebook Viewer</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">
  
  <meta name="robots" content="noindex,nofollow">
  

  <!--NEW RELIC Start Perf Measurement-->
  
  <!--NREND-->

  <!-- Le styles -->
  <link href="/static/build/styles.css" rel="stylesheet">

  <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
  <!--[if lt IE 9]>
    <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->

  <!-- Le fav and touch icons -->
  <link rel="shortcut icon" href="/static/ico/ipynb_icon_16x16.png">
  <link rel="apple-touch-icon-precomposed" sizes="144x144"
        href="/static/ico/apple-touch-icon-144-precomposed.png">
  <link rel="apple-touch-icon-precomposed" sizes="114x114"
        href="/static/ico/apple-touch-icon-114-precomposed.png">
  <link rel="apple-touch-icon-precomposed" sizes="72x72"
        href="/static/ico/apple-touch-icon-72-precomposed.png">
  <link rel="apple-touch-icon-precomposed"
        href="/static/ico/apple-touch-icon-57-precomposed.png">
  
  

  

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Notebook on nbviewer">
  <meta name="twitter:description" content="Check out this Jupyter notebook!">

  
  <meta name="twitter:domain" content="nbviewer.jupyter.org">
  <meta name="twitter:image:src" content="http://ipython.org/ipython-doc/dev/_images/ipynb_icon_128x128.png">

  
    <link href="/static/build/notebook.css" rel="stylesheet">
  

  

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML" type="text/javascript">
    </script>
    <script type="text/javascript">
      init_mathjax = function() {
        if (window.MathJax) {
          // MathJax loaded
          MathJax.Hub.Config({
            TeX: {
              equationNumbers: {
                autoNumber: "AMS",
                useLabelIds: true
              }
            },
            tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"] ],
              displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
              processEscapes: true,
              processEnvironments: true
            },
            displayAlign: 'center',
            "HTML-CSS": {
              styles: {'.MathJax_Display': {"margin": 0}},
              linebreaks: { automatic: true }
            }
          });
          MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
      }
      init_mathjax();
    </script>
  

  
    <script>
      (function() {
        function addWidgetsRenderer() {
          var mimeElement = document.querySelector('script[type="application/vnd.jupyter.widget-view+json"]');
          var scriptElement = document.createElement('script');
          var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js';
          var widgetState;

          try {
            widgetState = mimeElement && JSON.parse(mimeElement.innerHTML);

            if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) {
              widgetRendererSrc = 'https://unpkg.com/jupyter-js-widgets@*/dist/embed.js';
            }
          } catch(e) {}

          scriptElement.src = widgetRendererSrc;
          document.body.appendChild(scriptElement);
        }

        document.addEventListener('DOMContentLoaded', addWidgetsRenderer);
      }());
    </script>
  

</head>

<body class="nbviewer">

  <!-- These are loaded at the top of the body so they are available to
       notebook cells when they are loaded below. -->
  <script src="/static/components/jquery/dist/jquery.min.js"></script>
  <script src="/static/components/requirejs/require.js"></script>
  <script src="/static/components/moment/min/moment.min.js"></script>
<!-- Navbar
================================================== -->
  <nav id="menubar" class="navbar navbar-default navbar-fixed-top" data-spy="affix">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse">
          <span class="sr-only">Toggle navigation</span>
          <i class="fa fa-bars"></i>
        </button>
        <a class="navbar-brand" href="/">
          <img src="/static/img/nav_logo.svg" width="159"/>
        </a>
      </div>

      <div class="collapse navbar-collapse">
        <ul class="nav navbar-nav navbar-right">
          <li>
            <a class="active" href="https://jupyter.org">JUPYTER</a>
          </li>
          <li>
    <a href="/faq" title="FAQ" >
      
        <span>FAQ</span>
      
    </a>
  </li>

          
  
    
  
    
      
        <li>
    <a href="script/github/anubhabPanda/END_Phase1/blob/main/Week4/S4_Assignment_Solution.ipynb" title="View as Code" >
      <span class="fa fa-code fa-2x menu-icon"></span>
      <span class="menu-text">View as Code</span>
    </a>
  </li>
      
    
  

  
    <li>
    <a href="#" title="Python 3 Kernel" >
      <span class="fa fa-server fa-2x menu-icon"></span>
      <span class="menu-text">Python 3 Kernel</span>
    </a>
  </li>
  

  
    <li>
    <a href="https://github.com/anubhabPanda/END_Phase1/blob/main/Week4/S4_Assignment_Solution.ipynb" title="View on GitHub" >
      <span class="fa fa-github fa-2x menu-icon"></span>
      <span class="menu-text">View on GitHub</span>
    </a>
  </li>
  

  
    <li>
    <a href="https://mybinder.org/v2/gh/anubhabPanda/END_Phase1/main?filepath=Week4/S4_Assignment_Solution.ipynb" title="Execute on Binder" >
      <span class="fa fa-icon-binder fa-2x menu-icon"></span>
      <span class="menu-text">Execute on Binder</span>
    </a>
  </li>
  

  <li>
    <a href="https://raw.githubusercontent.com/anubhabPanda/END_Phase1/main/Week4/S4_Assignment_Solution.ipynb" title="Download Notebook" download>
      <span class="fa fa-download fa-2x menu-icon"></span>
      <span class="menu-text">Download Notebook</span>
    </a>
  </li>

        </ul>
      </div><!-- /.navbar-collapse -->
      
      
    </div>
  </nav>

  <div class="container container-main">
    
  
  <ol class="breadcrumb">
    
      <li>
        <a href="/github/anubhabPanda/END_Phase1/tree/main">END_Phase1</a>
      </li>
    
      <li>
        <a href="/github/anubhabPanda/END_Phase1/tree/main/Week4">Week4</a>
      </li>
    
  </ol>
  
  <div id="notebook">
    <div id="notebook-container">
      <div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Mounted at /content/drive
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">cd</span> /content/drive/MyDrive/END/Week4
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>/content/drive/MyDrive/END/Week4
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torchtext</span> <span class="kn">import</span> <span class="n">data</span>
<span class="kn">from</span> <span class="nn">torchtext</span> <span class="kn">import</span> <span class="n">datasets</span>

<span class="n">SEED</span> <span class="o">=</span> <span class="mi">1234</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>

<span class="n">TEXT</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">Field</span><span class="p">(</span><span class="n">tokenize</span> <span class="o">=</span> <span class="s1">&#39;spacy&#39;</span><span class="p">,</span> <span class="n">include_lengths</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">LABEL</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">LabelField</span><span class="p">(</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torchtext</span> <span class="kn">import</span> <span class="n">datasets</span>

<span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">IMDB</span><span class="o">.</span><span class="n">splits</span><span class="p">(</span><span class="n">TEXT</span><span class="p">,</span> <span class="n">LABEL</span><span class="p">,</span> <span class="n">root</span> <span class="o">=</span> <span class="s1">&#39;data&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>aclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00&lt;?, ?B/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>downloading aclImdb_v1.tar.gz
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:03&lt;00:00, 22.5MB/s]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>

<span class="n">train_data</span><span class="p">,</span> <span class="n">valid_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_data</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[14]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(17500, 7500, 25000)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">MAX_VOCAB_SIZE</span> <span class="o">=</span> <span class="mi">25_000</span>

<span class="n">TEXT</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> 
                 <span class="n">max_size</span> <span class="o">=</span> <span class="n">MAX_VOCAB_SIZE</span><span class="p">,</span> 
                 <span class="n">vectors</span> <span class="o">=</span> <span class="s2">&quot;glove.6B.100d&quot;</span><span class="p">,</span> 
                 <span class="n">unk_init</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">.</span><span class="n">normal_</span><span class="p">)</span>

<span class="n">LABEL</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>.vector_cache/glove.6B.zip: 862MB [06:29, 2.22MB/s]                           
100%|█████████▉| 399241/400000 [00:17&lt;00:00, 22043.11it/s]</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[404]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">64</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

<span class="n">train_iterator</span><span class="p">,</span> <span class="n">valid_iterator</span><span class="p">,</span> <span class="n">test_iterator</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">BucketIterator</span><span class="o">.</span><span class="n">splits</span><span class="p">(</span>
    <span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">valid_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">),</span> 
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">sort_within_batch</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Reversing-the-text">Reversing the text<a class="anchor-link" href="#Reversing-the-text">&#182;</a></h2><p>We can use torch.flip or list reversal to reverse the text. Lets try it out on one batch of the text. torch.flip is more efficient than the second method shown later</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[405]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">one_batch</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">train_iterator</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">one_batch</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[405]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>tensor([[  11,  314,   11,  ...,    0,   25,  403],
        [ 290,   12,   19,  ...,  251,  333,    2],
        [  13,  282, 2352,  ...,    3, 7151, 1684],
        ...,
        [2606,   40,   16,  ...,    1,    1,    1],
        [ 880,  235,   24,  ...,    1,    1,    1],
        [   4,   88,    4,  ...,    1,    1,    1]], device=&#39;cuda:0&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Method-1:-Using-torch.flip">Method 1: Using torch.flip<a class="anchor-link" href="#Method-1:-Using-torch.flip">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[406]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">one_batch</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[406]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>tensor([[   4,   88,    4,  ...,    1,    1,    1],
        [ 880,  235,   24,  ...,    1,    1,    1],
        [2606,   40,   16,  ...,    1,    1,    1],
        ...,
        [  13,  282, 2352,  ...,    3, 7151, 1684],
        [ 290,   12,   19,  ...,  251,  333,    2],
        [  11,  314,   11,  ...,    0,   25,  403]], device=&#39;cuda:0&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Method-2:-Using-list-reversal-using-reversed-function">Method 2: Using list reversal using reversed function<a class="anchor-link" href="#Method-2:-Using-list-reversal-using-reversed-function">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Original text</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[407]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">TEXT</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">itos</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">one_batch</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[407]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;I believe that war films should try to convey the terror of war , avoid idealism and respect some rudimentary military principles . &lt;unk&gt; barely does the first . &lt;unk&gt; being a Russian war film , I was expecting patriotism , sentimentality , beautiful poetic pictures , a lush score , Slavic &lt;unk&gt; and cruel Germans . What I did n\&#39;t need was the naive love non - affair , the unrealistically silly war scenes and the abuse of the syrupy soundtrack in a film which avoided carefully all historical or political references ( &lt;unk&gt; , Nazism , Holocaust ) only to end on a passing but nonetheless insulting to our sense of history &lt;unk&gt; about &#34; liberating Poland &#34; . A missed opportunity as a film but not as propaganda apparently .&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Reversed text</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[408]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">([</span><span class="n">TEXT</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">itos</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">one_batch</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()])))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[408]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;. apparently propaganda as not but film a as opportunity missed A . &#34; Poland liberating &#34; about &lt;unk&gt; history of sense our to insulting nonetheless but passing a on end to only ) Holocaust , Nazism , &lt;unk&gt; ( references political or historical all carefully avoided which film a in soundtrack syrupy the of abuse the and scenes war silly unrealistically the , affair - non love naive the was need n\&#39;t did I What . Germans cruel and &lt;unk&gt; Slavic , score lush a , pictures poetic beautiful , sentimentality , patriotism expecting was I , film war Russian a being &lt;unk&gt; . first the does barely &lt;unk&gt; . principles military rudimentary some respect and idealism avoid , war of terror the convey to try should films war that believe I&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>This we have to do individually for each text using a for loop if we are using Method 2. Hence Method 1 is more efficient</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model-Definition">Model Definition<a class="anchor-link" href="#Model-Definition">&#182;</a></h2><p>Here we have to use 3 LSTM layers in a loop instead of using the layer parameter = 3 in the nn.LSTM layer.
This we can do using torch.Modulelist and passing the cell states and hidden states of one LSTM layer to other using a for loop</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[409]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[458]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">RNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">pad_idx</span><span class="p">):</span>
        
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">padding_idx</span> <span class="o">=</span> <span class="n">pad_idx</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multi_layered_rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multi_layered_rnn</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)]</span><span class="o">*</span><span class="p">(</span><span class="n">n_layers</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        
        
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">1</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">text_lengths</span><span class="p">):</span>
        
        <span class="c1">#text = [sent len, batch size]</span>
        
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>
        
        <span class="c1">#embedded = [sent len, batch size, emb dim]</span>
        
        <span class="c1">#pack sequence</span>
        <span class="n">packed_embedded</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">embedded</span><span class="p">,</span> <span class="n">text_lengths</span><span class="p">,</span> <span class="n">enforce_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">rnn</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_layered_rnn</span><span class="p">:</span>
          <span class="c1"># print(packed_embedded)</span>
          <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rnn</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">dropout</span><span class="o">.</span><span class="n">Dropout</span><span class="p">):</span> 
            <span class="n">packed_embedded</span><span class="p">,</span> <span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">cell</span><span class="p">)</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">(</span><span class="n">packed_embedded</span><span class="p">)</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="n">packed_embedded</span><span class="p">,</span> <span class="n">packed_lengths</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pad_packed_sequence</span><span class="p">(</span><span class="n">packed_embedded</span><span class="p">)</span>
            <span class="n">packed_embedded</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">rnn</span><span class="p">(</span><span class="n">packed_embedded</span><span class="p">),</span> <span class="n">packed_lengths</span><span class="p">,</span> <span class="n">enforce_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        
        <span class="c1">#unpack sequence</span>
        <span class="c1"># output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)</span>

        <span class="c1">#output = [sent len, batch size, hid dim * num directions]</span>
        <span class="c1">#output over padding tokens are zero tensors</span>
        
        <span class="c1">#hidden = [num layers * num directions, batch size, hid dim]</span>
        <span class="c1">#cell = [num layers * num directions, batch size, hid dim]</span>
        
        <span class="c1">#concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers</span>
        <span class="c1">#and apply dropout</span>
        
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">hidden</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,:,:])</span>
                
        <span class="c1">#hidden = [batch size, hid dim * num directions]</span>
            
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[459]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">INPUT_DIM</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">TEXT</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
<span class="n">EMBEDDING_DIM</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">HIDDEN_DIM</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">OUTPUT_DIM</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">N_LAYERS</span> <span class="o">=</span> <span class="mi">3</span>
<span class="c1"># BIDIRECTIONAL = True</span>
<span class="n">DROPOUT</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">PAD_IDX</span> <span class="o">=</span> <span class="n">TEXT</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">stoi</span><span class="p">[</span><span class="n">TEXT</span><span class="o">.</span><span class="n">pad_token</span><span class="p">]</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">RNN</span><span class="p">(</span><span class="n">INPUT_DIM</span><span class="p">,</span> 
            <span class="n">EMBEDDING_DIM</span><span class="p">,</span> 
            <span class="n">HIDDEN_DIM</span><span class="p">,</span> 
            <span class="n">OUTPUT_DIM</span><span class="p">,</span> 
            <span class="n">N_LAYERS</span><span class="p">,</span> 
            <span class="n">DROPOUT</span><span class="p">,</span> 
            <span class="n">PAD_IDX</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[460]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>RNN(
  (embedding): Embedding(25002, 100, padding_idx=1)
  (dropout): Dropout(p=0.2, inplace=False)
  (multi_layered_rnn): ModuleList(
    (0): LSTM(100, 256)
    (1): Dropout(p=0.2, inplace=False)
    (2): LSTM(256, 256)
    (3): Dropout(p=0.2, inplace=False)
    (4): LSTM(256, 256)
  )
  (fc): Linear(in_features=256, out_features=1, bias=True)
)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[461]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">count_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The model has </span><span class="si">{</span><span class="n">count_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="si">:</span><span class="s1">,</span><span class="si">}</span><span class="s1"> trainable parameters&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>The model has 3,393,385 trainable parameters
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[462]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pretrained_embeddings</span> <span class="o">=</span> <span class="n">TEXT</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">vectors</span>

<span class="nb">print</span><span class="p">(</span><span class="n">pretrained_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([25002, 100])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[463]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">pretrained_embeddings</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[463]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],
        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],
        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],
        ...,
        [-0.0218, -0.0350,  0.1495,  ..., -0.5508,  0.4874, -0.1341],
        [-0.6345,  0.5735, -0.3945,  ..., -0.4865,  0.1097,  0.5122],
        [ 0.6406,  0.3674,  0.8373,  ..., -0.1512, -0.0284, -0.1952]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[464]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">UNK_IDX</span> <span class="o">=</span> <span class="n">TEXT</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">stoi</span><span class="p">[</span><span class="n">TEXT</span><span class="o">.</span><span class="n">unk_token</span><span class="p">]</span>

<span class="n">model</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">UNK_IDX</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">EMBEDDING_DIM</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">PAD_IDX</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">EMBEDDING_DIM</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],
        ...,
        [-0.0218, -0.0350,  0.1495,  ..., -0.5508,  0.4874, -0.1341],
        [-0.6345,  0.5735, -0.3945,  ..., -0.4865,  0.1097,  0.5122],
        [ 0.6406,  0.3674,  0.8373,  ..., -0.1512, -0.0284, -0.1952]])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[465]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="c1"># optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[466]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">criterion</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[467]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">binary_accuracy</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1">#round predictions to the closest integer</span>
    <span class="n">rounded_preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">preds</span><span class="p">))</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="p">(</span><span class="n">rounded_preds</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="c1">#convert into float for division </span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">correct</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">acc</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>In the train function we are reversing the text online as we get the data from the batch. This was it will be less memory intensive</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[468]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">iterator</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">):</span>
    
    <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">epoch_acc</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">iterator</span><span class="p">:</span>
        
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        
        <span class="n">text</span><span class="p">,</span> <span class="n">text_lengths</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">text</span>
        <span class="n">text_lengths</span> <span class="o">=</span> <span class="n">text_lengths</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
        <span class="c1">#Reversing the text</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">))</span>

        <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">text_lengths</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">label</span><span class="p">)</span>
        
        <span class="n">acc</span> <span class="o">=</span> <span class="n">binary_accuracy</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">label</span><span class="p">)</span>
        
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">epoch_acc</span> <span class="o">+=</span> <span class="n">acc</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        
    <span class="k">return</span> <span class="n">epoch_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">iterator</span><span class="p">),</span> <span class="n">epoch_acc</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[469]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">iterator</span><span class="p">,</span> <span class="n">criterion</span><span class="p">):</span>
    
    <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">epoch_acc</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">iterator</span><span class="p">:</span>

            <span class="n">text</span><span class="p">,</span> <span class="n">text_lengths</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">text</span>
            <span class="n">text_lengths</span> <span class="o">=</span> <span class="n">text_lengths</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">text_lengths</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">label</span><span class="p">)</span>
            
            <span class="n">acc</span> <span class="o">=</span> <span class="n">binary_accuracy</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">label</span><span class="p">)</span>

            <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">epoch_acc</span> <span class="o">+=</span> <span class="n">acc</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        
    <span class="k">return</span> <span class="n">epoch_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">iterator</span><span class="p">),</span> <span class="n">epoch_acc</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[470]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>

<span class="k">def</span> <span class="nf">epoch_time</span><span class="p">(</span><span class="n">start_time</span><span class="p">,</span> <span class="n">end_time</span><span class="p">):</span>
    <span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>
    <span class="n">elapsed_mins</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">elapsed_time</span> <span class="o">/</span> <span class="mi">60</span><span class="p">)</span>
    <span class="n">elapsed_secs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">elapsed_time</span> <span class="o">-</span> <span class="p">(</span><span class="n">elapsed_mins</span> <span class="o">*</span> <span class="mi">60</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">elapsed_mins</span><span class="p">,</span> <span class="n">elapsed_secs</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[471]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">N_EPOCHS</span> <span class="o">=</span> <span class="mi">20</span>

<span class="n">best_valid_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_EPOCHS</span><span class="p">):</span>

    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    
    <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_iterator</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
    <span class="n">valid_loss</span><span class="p">,</span> <span class="n">valid_acc</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">valid_iterator</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
    
    <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="n">epoch_mins</span><span class="p">,</span> <span class="n">epoch_secs</span> <span class="o">=</span> <span class="n">epoch_time</span><span class="p">(</span><span class="n">start_time</span><span class="p">,</span> <span class="n">end_time</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">valid_loss</span> <span class="o">&lt;</span> <span class="n">best_valid_loss</span><span class="p">:</span>
        <span class="n">best_valid_loss</span> <span class="o">=</span> <span class="n">valid_loss</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;tut2-model.pt&#39;</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">:</span><span class="s1">02</span><span class="si">}</span><span class="s1"> | Epoch Time: </span><span class="si">{</span><span class="n">epoch_mins</span><span class="si">}</span><span class="s1">m </span><span class="si">{</span><span class="n">epoch_secs</span><span class="si">}</span><span class="s1">s&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1"> | Train Acc: </span><span class="si">{</span><span class="n">train_acc</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1"> Val. Loss: </span><span class="si">{</span><span class="n">valid_loss</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1"> |  Val. Acc: </span><span class="si">{</span><span class="n">valid_acc</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch: 01 | Epoch Time: 0m 31s
	Train Loss: 0.679 | Train Acc: 57.02%
	 Val. Loss: 0.662 |  Val. Acc: 62.69%
Epoch: 02 | Epoch Time: 0m 32s
	Train Loss: 0.659 | Train Acc: 60.13%
	 Val. Loss: 0.672 |  Val. Acc: 65.51%
Epoch: 03 | Epoch Time: 0m 31s
	Train Loss: 0.506 | Train Acc: 75.81%
	 Val. Loss: 0.362 |  Val. Acc: 84.97%
Epoch: 04 | Epoch Time: 0m 32s
	Train Loss: 0.331 | Train Acc: 86.30%
	 Val. Loss: 0.346 |  Val. Acc: 85.90%
Epoch: 05 | Epoch Time: 0m 32s
	Train Loss: 0.293 | Train Acc: 88.18%
	 Val. Loss: 0.314 |  Val. Acc: 87.20%
Epoch: 06 | Epoch Time: 0m 31s
	Train Loss: 0.233 | Train Acc: 91.00%
	 Val. Loss: 0.319 |  Val. Acc: 87.50%
Epoch: 07 | Epoch Time: 0m 32s
	Train Loss: 0.198 | Train Acc: 92.61%
	 Val. Loss: 0.373 |  Val. Acc: 85.64%
Epoch: 08 | Epoch Time: 0m 32s
	Train Loss: 0.180 | Train Acc: 93.31%
	 Val. Loss: 0.409 |  Val. Acc: 85.76%
Epoch: 09 | Epoch Time: 0m 32s
	Train Loss: 0.150 | Train Acc: 94.61%
	 Val. Loss: 0.306 |  Val. Acc: 88.05%
Epoch: 10 | Epoch Time: 0m 31s
	Train Loss: 0.131 | Train Acc: 95.30%
	 Val. Loss: 0.399 |  Val. Acc: 85.84%
Epoch: 11 | Epoch Time: 0m 32s
	Train Loss: 0.104 | Train Acc: 96.33%
	 Val. Loss: 0.379 |  Val. Acc: 87.98%
Epoch: 12 | Epoch Time: 0m 32s
	Train Loss: 0.101 | Train Acc: 96.59%
	 Val. Loss: 0.404 |  Val. Acc: 87.49%
Epoch: 13 | Epoch Time: 0m 31s
	Train Loss: 0.076 | Train Acc: 97.51%
	 Val. Loss: 0.408 |  Val. Acc: 87.64%
Epoch: 14 | Epoch Time: 0m 31s
	Train Loss: 0.062 | Train Acc: 97.96%
	 Val. Loss: 0.472 |  Val. Acc: 87.37%
Epoch: 15 | Epoch Time: 0m 32s
	Train Loss: 0.056 | Train Acc: 98.28%
	 Val. Loss: 0.448 |  Val. Acc: 87.56%
Epoch: 16 | Epoch Time: 0m 31s
	Train Loss: 0.048 | Train Acc: 98.53%
	 Val. Loss: 0.477 |  Val. Acc: 87.70%
Epoch: 17 | Epoch Time: 0m 31s
	Train Loss: 0.046 | Train Acc: 98.49%
	 Val. Loss: 0.506 |  Val. Acc: 87.46%
Epoch: 18 | Epoch Time: 0m 32s
	Train Loss: 0.034 | Train Acc: 99.07%
	 Val. Loss: 0.519 |  Val. Acc: 87.09%
Epoch: 19 | Epoch Time: 0m 31s
	Train Loss: 0.037 | Train Acc: 98.87%
	 Val. Loss: 0.475 |  Val. Acc: 87.64%
Epoch: 20 | Epoch Time: 0m 32s
	Train Loss: 0.035 | Train Acc: 98.96%
	 Val. Loss: 0.477 |  Val. Acc: 87.80%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[472]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;tut2-model.pt&#39;</span><span class="p">))</span>

<span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_iterator</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Test Loss: </span><span class="si">{</span><span class="n">test_loss</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1"> | Test Acc: </span><span class="si">{</span><span class="n">test_acc</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test Loss: 0.338 | Test Acc: 85.84%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[473]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">spacy</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;en&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">predict_sentiment</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sentence</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">tokenized</span> <span class="o">=</span> <span class="p">[</span><span class="n">tok</span><span class="o">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">tok</span> <span class="ow">in</span> <span class="n">nlp</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">sentence</span><span class="p">)]</span>
    <span class="n">rev_tokenized</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">tokenized</span><span class="p">))</span>
    <span class="n">indexed</span> <span class="o">=</span> <span class="p">[</span><span class="n">TEXT</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">stoi</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">rev_tokenized</span><span class="p">]</span>
    <span class="n">length</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">indexed</span><span class="p">)]</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">indexed</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">length_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">length</span><span class="p">)</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">length_tensor</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">prediction</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[474]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentence</span> <span class="o">=</span> <span class="s2">&quot;This film is terrible&quot;</span>
<span class="n">predict_sentiment</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[474]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.0022441146429628134</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[475]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentence</span> <span class="o">=</span> <span class="s2">&quot;This film is awesome&quot;</span>
<span class="n">predict_sentiment</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[475]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9864891767501831</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
 


    </div>
  </div>

  </div>


  
    <footer class="footer hidden-print">
      <div class="container">
        <div class="col-md-4">
          <p>
            This website does not host notebooks, it only renders notebooks
            available on other websites.
          </p>
        </div>

        <div class="col-md-4">
          <p>
            Delivered by <a href="https://www.fastly.com/">Fastly</a>,
            Rendered by <a href="https://ovhcloud.com">OVHcloud</a>
          </p>
          <p>
            nbviewer GitHub <a href="https://github.com/jupyter/nbviewer">repository</a>.
          </p>
        </div>

        <div class="col-md-4">
          
  
            
              <p>
                nbviewer version:
                <a href="https://github.com/jupyter/nbviewer/commit/cf693bda747f1f98e31a6005c874fbe2ee7fb4cc">
                  cf693bd
                </a>
              </p>
            
          
  
  <p>
    nbconvert version: <a href="https://github.com/jupyter/nbconvert/releases/tag/5.6.1">
      5.6.1
    </a>
  </p>
  

          
  
  
  <p>
    Rendered
    <span class='date' data-date='Thu, 19 Nov 2020 19:38:35 UTC' title='Thu, 19 Nov 2020 19:38:35 UTC'>(Thu, 19 Nov 2020 19:38:35 UTC)</span>
  </p>
  

        </div>
      </div>
    </footer>
  

  <script src="/static/components/bootstrap/js/bootstrap.min.js"></script>
  <script src="/static/components/headroom.js/dist/headroom.min.js"></script>
  <script src="/static/components/headroom.js/dist/jQuery.headroom.min.js"></script>

  
  
  <script>
    $(function(){ $("#menubar").headroom({
      tolerance: 5,
      offset: 205,
      classes: {
        initial: "animated",
        pinned: "slideInDown",
        unpinned: "slideOutUp"
      }
    })});
  </script>


  
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-52617120-5', 'auto',
       {'storage': 'none'});
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
  </script>
  
  <script>
    require({
        paths: {
          moment: "/static/components/moment/min/moment.min.js"
        }
      }, ["moment"], function(moment){
      var date = $("footer .date"),
        m = moment(new Date(date.data('date'))),
        update = function(){ date.text(m.fromNow()); };
      setInterval(update, 61*1000);
      update();
      var w = $(window).scroll(function(event){
        $("body").toggleClass("scrolled", w.scrollTop() > 0);
      });
    });
  </script>

  <!--NEW RELIC Stop Perf Measurement-->
  
  <!--NEW RELIC End-->
</body>
</html>